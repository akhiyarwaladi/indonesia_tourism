{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Clustering: Indonesia Tourism Dataset\n",
    "## Perbandingan K-Means dan Hierarchical Clustering\n",
    "\n",
    "Tutorial ini mencakup:\n",
    "1. **Eksplorasi Data** - Missing values, outliers, dan data quality\n",
    "2. **Integrasi Data** - Menggabungkan beberapa file CSV\n",
    "3. **Preprocessing** - Handling missing values, outliers, dan normalisasi\n",
    "4. **Clustering** - K-Means dan Hierarchical dengan berbagai parameter\n",
    "5. **Perbandingan** - Hasil dengan/tanpa preprocessing dan parameter berbeda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "### Dataset terdiri dari 4 file:\n",
    "- `tourism_with_id.csv` - Data destinasi wisata dengan atribut lengkap\n",
    "- `tourism_rating.csv` - Rating user untuk destinasi\n",
    "- `user.csv` - Data pengguna\n",
    "- `package_tourism.csv` - Paket wisata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "tourism = pd.read_csv('tourism_with_id.csv')\n",
    "ratings = pd.read_csv('tourism_rating.csv')\n",
    "users = pd.read_csv('user.csv')\n",
    "packages = pd.read_csv('package_tourism.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Tourism: {tourism.shape}\")\n",
    "print(f\"Ratings: {ratings.shape}\")\n",
    "print(f\"Users: {users.shape}\")\n",
    "print(f\"Packages: {packages.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview tourism data\n",
    "print(\"\\n=== TOURISM DATA ===\")\n",
    "print(tourism.head())\n",
    "print(f\"\\nColumns: {tourism.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{tourism.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview ratings data\n",
    "print(\"\\n=== RATINGS DATA ===\")\n",
    "print(ratings.head())\n",
    "print(f\"\\nColumns: {ratings.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview users data\n",
    "print(\"\\n=== USERS DATA ===\")\n",
    "print(users.head())\n",
    "print(f\"\\nColumns: {users.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview packages data\n",
    "print(\"\\n=== PACKAGES DATA ===\")\n",
    "print(packages.head())\n",
    "print(f\"\\nColumns: {packages.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df, name):\n",
    "    print(f\"\\n=== Missing Values in {name} ===\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = 100 * missing / len(df)\n",
    "    missing_table = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_table[missing_table['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
    "    \n",
    "    if missing.sum() == 0:\n",
    "        print(\"No missing values found!\")\n",
    "    \n",
    "    return missing_table\n",
    "\n",
    "missing_tourism = check_missing_values(tourism, 'Tourism')\n",
    "missing_ratings = check_missing_values(ratings, 'Ratings')\n",
    "missing_users = check_missing_values(users, 'Users')\n",
    "missing_packages = check_missing_values(packages, 'Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for tourism data\n",
    "print(\"\\n=== Tourism Data - Statistical Summary ===\")\n",
    "print(tourism.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for ratings data\n",
    "print(\"\\n=== Ratings Data - Statistical Summary ===\")\n",
    "print(ratings.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tourism duplicates: {tourism.duplicated().sum()}\")\n",
    "print(f\"Ratings duplicates: {ratings.duplicated().sum()}\")\n",
    "print(f\"Users duplicates: {users.duplicated().sum()}\")\n",
    "print(f\"Packages duplicates: {packages.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Check Outliers (for numerical columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, columns):\n",
    "    outliers_dict = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outliers_dict[col] = len(outliers)\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "# Check outliers in tourism data (numerical columns only)\n",
    "numeric_cols = tourism.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"\\n=== Outliers Detection (IQR Method) ===\")\n",
    "outliers = detect_outliers_iqr(tourism, numeric_cols)\n",
    "for col, count in outliers.items():\n",
    "    print(f\"{col}: {count} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Visualize Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features in tourism data\n",
    "numeric_cols = tourism.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    fig, axes = plt.subplots(len(numeric_cols), 2, figsize=(15, 5*len(numeric_cols)))\n",
    "    \n",
    "    if len(numeric_cols) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, col in enumerate(numeric_cols):\n",
    "        # Histogram\n",
    "        axes[idx, 0].hist(tourism[col].dropna(), bins=30, edgecolor='black')\n",
    "        axes[idx, 0].set_title(f'Distribution of {col}')\n",
    "        axes[idx, 0].set_xlabel(col)\n",
    "        axes[idx, 0].set_ylabel('Frequency')\n",
    "        \n",
    "        # Boxplot\n",
    "        axes[idx, 1].boxplot(tourism[col].dropna())\n",
    "        axes[idx, 1].set_title(f'Boxplot of {col}')\n",
    "        axes[idx, 1].set_ylabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical columns found for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Integration\n",
    "### Menggabungkan dataset untuk mendapatkan informasi yang lebih lengkap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate ratings for each place\n",
    "ratings_agg = ratings.groupby('Place_Id').agg({\n",
    "    'Place_Ratings': ['mean', 'count', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "ratings_agg.columns = ['Place_Id', 'Avg_Rating', 'Rating_Count', 'Rating_Std']\n",
    "ratings_agg['Rating_Std'] = ratings_agg['Rating_Std'].fillna(0)  # Fill NaN std with 0\n",
    "\n",
    "print(\"\\n=== Aggregated Ratings ===\")\n",
    "print(ratings_agg.head())\n",
    "print(f\"Shape: {ratings_agg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tourism data with aggregated ratings\n",
    "tourism_merged = tourism.merge(ratings_agg, on='Place_Id', how='left')\n",
    "\n",
    "print(\"\\n=== Merged Tourism Data ===\")\n",
    "print(tourism_merged.head())\n",
    "print(f\"\\nShape: {tourism_merged.shape}\")\n",
    "print(f\"Columns: {tourism_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "### 5.1 Identify Features for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for clustering\n",
    "# Exclude ID columns and names\n",
    "exclude_cols = ['Place_Id', 'Place_Name']\n",
    "categorical_cols = tourism_merged.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = [col for col in tourism_merged.select_dtypes(include=[np.number]).columns \n",
    "                  if col not in exclude_cols]\n",
    "\n",
    "print(f\"Numerical columns for clustering: {numerical_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean dataset for clustering\n",
    "# For this tutorial, we'll focus on numerical features\n",
    "clustering_data = tourism_merged[numerical_cols].copy()\n",
    "\n",
    "print(f\"\\nClustering data shape: {clustering_data.shape}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(clustering_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with median (robust to outliers)\n",
    "clustering_data_filled = clustering_data.fillna(clustering_data.median())\n",
    "\n",
    "print(f\"Missing values after filling:\")\n",
    "print(clustering_data_filled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Handle Outliers (Optional - using IQR capping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(df):\n",
    "    \"\"\"Cap outliers using IQR method\"\"\"\n",
    "    df_capped = df.copy()\n",
    "    \n",
    "    for col in df_capped.columns:\n",
    "        Q1 = df_capped[col].quantile(0.25)\n",
    "        Q3 = df_capped[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Cap the outliers\n",
    "        df_capped[col] = df_capped[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return df_capped\n",
    "\n",
    "clustering_data_capped = cap_outliers(clustering_data_filled)\n",
    "print(\"Outliers capped successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization (Z-score normalization)\n",
    "scaler_standard = StandardScaler()\n",
    "clustering_data_scaled = scaler_standard.fit_transform(clustering_data_capped)\n",
    "clustering_data_scaled_df = pd.DataFrame(clustering_data_scaled, \n",
    "                                          columns=clustering_data_capped.columns)\n",
    "\n",
    "print(\"\\n=== Data After Preprocessing (Scaled) ===\")\n",
    "print(clustering_data_scaled_df.head())\n",
    "print(f\"\\nShape: {clustering_data_scaled_df.shape}\")\n",
    "print(f\"\\nMean of features (should be ~0): {clustering_data_scaled_df.mean().values}\")\n",
    "print(f\"\\nStd of features (should be ~1): {clustering_data_scaled_df.std().values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = clustering_data_filled.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. K-Means Clustering\n",
    "### 6.1 Elbow Method - Find Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(clustering_data_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette scores for different K values\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(clustering_data_scaled)\n",
    "    score = silhouette_score(clustering_data_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"K={k}: Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal K')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal K based on Silhouette Score: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 K-Means with Preprocessing (Optimal K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means with optimal K (let's use K=4 as example, adjust based on your elbow/silhouette)\n",
    "optimal_k = 4\n",
    "\n",
    "kmeans_preprocessed = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "labels_kmeans_preprocessed = kmeans_preprocessed.fit_predict(clustering_data_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "silhouette_kmeans = silhouette_score(clustering_data_scaled, labels_kmeans_preprocessed)\n",
    "davies_bouldin_kmeans = davies_bouldin_score(clustering_data_scaled, labels_kmeans_preprocessed)\n",
    "calinski_kmeans = calinski_harabasz_score(clustering_data_scaled, labels_kmeans_preprocessed)\n",
    "\n",
    "print(f\"\\n=== K-Means with Preprocessing (K={optimal_k}) ===\")\n",
    "print(f\"Silhouette Score: {silhouette_kmeans:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_kmeans:.4f} (lower is better)\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_kmeans:.4f} (higher is better)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(labels_kmeans_preprocessed).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 K-Means WITHOUT Preprocessing (untuk perbandingan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means WITHOUT scaling/outlier handling\n",
    "kmeans_no_preprocess = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "labels_kmeans_no_preprocess = kmeans_no_preprocess.fit_predict(clustering_data_filled)\n",
    "\n",
    "# Calculate metrics\n",
    "silhouette_kmeans_no = silhouette_score(clustering_data_filled, labels_kmeans_no_preprocess)\n",
    "davies_bouldin_kmeans_no = davies_bouldin_score(clustering_data_filled, labels_kmeans_no_preprocess)\n",
    "calinski_kmeans_no = calinski_harabasz_score(clustering_data_filled, labels_kmeans_no_preprocess)\n",
    "\n",
    "print(f\"\\n=== K-Means WITHOUT Preprocessing (K={optimal_k}) ===\")\n",
    "print(f\"Silhouette Score: {silhouette_kmeans_no:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_kmeans_no:.4f} (lower is better)\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_kmeans_no:.4f} (higher is better)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(labels_kmeans_no_preprocess).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Comparison: With vs Without Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "comparison_kmeans = pd.DataFrame({\n",
    "    'Metric': ['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index'],\n",
    "    'With Preprocessing': [silhouette_kmeans, davies_bouldin_kmeans, calinski_kmeans],\n",
    "    'Without Preprocessing': [silhouette_kmeans_no, davies_bouldin_kmeans_no, calinski_kmeans_no]\n",
    "})\n",
    "\n",
    "print(\"\\n=== K-Means: Impact of Preprocessing ===\")\n",
    "print(comparison_kmeans)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    values = comparison_kmeans[comparison_kmeans['Metric'] == metric][['With Preprocessing', 'Without Preprocessing']].values[0]\n",
    "    axes[idx].bar(['With Preprocessing', 'Without Preprocessing'], values, color=['green', 'orange'])\n",
    "    axes[idx].set_title(metric)\n",
    "    axes[idx].set_ylabel('Score')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Test Different K Values (Parameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different K values\n",
    "k_values = [3, 4, 5, 6]\n",
    "results_different_k = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(clustering_data_scaled)\n",
    "    \n",
    "    silhouette = silhouette_score(clustering_data_scaled, labels)\n",
    "    davies_bouldin = davies_bouldin_score(clustering_data_scaled, labels)\n",
    "    calinski = calinski_harabasz_score(clustering_data_scaled, labels)\n",
    "    \n",
    "    results_different_k.append({\n",
    "        'K': k,\n",
    "        'Silhouette': silhouette,\n",
    "        'Davies-Bouldin': davies_bouldin,\n",
    "        'Calinski-Harabasz': calinski\n",
    "    })\n",
    "\n",
    "results_k_df = pd.DataFrame(results_different_k)\n",
    "print(\"\\n=== K-Means: Different K Values ===\")\n",
    "print(results_k_df)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].plot(results_k_df['K'], results_k_df['Silhouette'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_title('Silhouette Score vs K')\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(results_k_df['K'], results_k_df['Davies-Bouldin'], 'ro-', linewidth=2, markersize=8)\n",
    "axes[1].set_title('Davies-Bouldin Index vs K')\n",
    "axes[1].set_xlabel('K')\n",
    "axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(results_k_df['K'], results_k_df['Calinski-Harabasz'], 'go-', linewidth=2, markersize=8)\n",
    "axes[2].set_title('Calinski-Harabasz Index vs K')\n",
    "axes[2].set_xlabel('K')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hierarchical Clustering\n",
    "### 7.1 Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dendrogram (using sample of data if too large)\n",
    "sample_size = min(100, len(clustering_data_scaled))\n",
    "sample_indices = np.random.choice(len(clustering_data_scaled), sample_size, replace=False)\n",
    "sample_data = clustering_data_scaled[sample_indices]\n",
    "\n",
    "# Different linkage methods\n",
    "linkage_methods = ['ward', 'complete', 'average', 'single']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    Z = linkage(sample_data, method=method)\n",
    "    dendrogram(Z, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Dendrogram - {method.capitalize()} Linkage')\n",
    "    axes[idx].set_xlabel('Sample Index')\n",
    "    axes[idx].set_ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Hierarchical Clustering with Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering with preprocessing (ward linkage)\n",
    "hierarchical_preprocessed = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
    "labels_hierarchical_preprocessed = hierarchical_preprocessed.fit_predict(clustering_data_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "silhouette_hierarchical = silhouette_score(clustering_data_scaled, labels_hierarchical_preprocessed)\n",
    "davies_bouldin_hierarchical = davies_bouldin_score(clustering_data_scaled, labels_hierarchical_preprocessed)\n",
    "calinski_hierarchical = calinski_harabasz_score(clustering_data_scaled, labels_hierarchical_preprocessed)\n",
    "\n",
    "print(f\"\\n=== Hierarchical Clustering with Preprocessing (K={optimal_k}, Ward linkage) ===\")\n",
    "print(f\"Silhouette Score: {silhouette_hierarchical:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_hierarchical:.4f} (lower is better)\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_hierarchical:.4f} (higher is better)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(labels_hierarchical_preprocessed).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Hierarchical Clustering WITHOUT Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering WITHOUT preprocessing\n",
    "hierarchical_no_preprocess = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
    "labels_hierarchical_no_preprocess = hierarchical_no_preprocess.fit_predict(clustering_data_filled)\n",
    "\n",
    "# Calculate metrics\n",
    "silhouette_hierarchical_no = silhouette_score(clustering_data_filled, labels_hierarchical_no_preprocess)\n",
    "davies_bouldin_hierarchical_no = davies_bouldin_score(clustering_data_filled, labels_hierarchical_no_preprocess)\n",
    "calinski_hierarchical_no = calinski_harabasz_score(clustering_data_filled, labels_hierarchical_no_preprocess)\n",
    "\n",
    "print(f\"\\n=== Hierarchical Clustering WITHOUT Preprocessing (K={optimal_k}, Ward linkage) ===\")\n",
    "print(f\"Silhouette Score: {silhouette_hierarchical_no:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_hierarchical_no:.4f} (lower is better)\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_hierarchical_no:.4f} (higher is better)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(labels_hierarchical_no_preprocess).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Test Different Linkage Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different linkage methods\n",
    "linkage_methods = ['ward', 'complete', 'average', 'single']\n",
    "results_linkage = []\n",
    "\n",
    "for method in linkage_methods:\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage=method)\n",
    "    labels = hierarchical.fit_predict(clustering_data_scaled)\n",
    "    \n",
    "    silhouette = silhouette_score(clustering_data_scaled, labels)\n",
    "    davies_bouldin = davies_bouldin_score(clustering_data_scaled, labels)\n",
    "    calinski = calinski_harabasz_score(clustering_data_scaled, labels)\n",
    "    \n",
    "    results_linkage.append({\n",
    "        'Linkage': method,\n",
    "        'Silhouette': silhouette,\n",
    "        'Davies-Bouldin': davies_bouldin,\n",
    "        'Calinski-Harabasz': calinski\n",
    "    })\n",
    "\n",
    "results_linkage_df = pd.DataFrame(results_linkage)\n",
    "print(\"\\n=== Hierarchical Clustering: Different Linkage Methods ===\")\n",
    "print(results_linkage_df)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "x_pos = np.arange(len(linkage_methods))\n",
    "\n",
    "axes[0].bar(x_pos, results_linkage_df['Silhouette'])\n",
    "axes[0].set_title('Silhouette Score by Linkage Method')\n",
    "axes[0].set_xlabel('Linkage Method')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(linkage_methods)\n",
    "\n",
    "axes[1].bar(x_pos, results_linkage_df['Davies-Bouldin'], color='orange')\n",
    "axes[1].set_title('Davies-Bouldin Index by Linkage Method')\n",
    "axes[1].set_xlabel('Linkage Method')\n",
    "axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(linkage_methods)\n",
    "\n",
    "axes[2].bar(x_pos, results_linkage_df['Calinski-Harabasz'], color='green')\n",
    "axes[2].set_title('Calinski-Harabasz Index by Linkage Method')\n",
    "axes[2].set_xlabel('Linkage Method')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[2].set_xticks(x_pos)\n",
    "axes[2].set_xticklabels(linkage_methods)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Test Different Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different number of clusters for hierarchical\n",
    "k_values_hier = [3, 4, 5, 6]\n",
    "results_hier_k = []\n",
    "\n",
    "for k in k_values_hier:\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = hierarchical.fit_predict(clustering_data_scaled)\n",
    "    \n",
    "    silhouette = silhouette_score(clustering_data_scaled, labels)\n",
    "    davies_bouldin = davies_bouldin_score(clustering_data_scaled, labels)\n",
    "    calinski = calinski_harabasz_score(clustering_data_scaled, labels)\n",
    "    \n",
    "    results_hier_k.append({\n",
    "        'K': k,\n",
    "        'Silhouette': silhouette,\n",
    "        'Davies-Bouldin': davies_bouldin,\n",
    "        'Calinski-Harabasz': calinski\n",
    "    })\n",
    "\n",
    "results_hier_k_df = pd.DataFrame(results_hier_k)\n",
    "print(\"\\n=== Hierarchical Clustering: Different K Values ===\")\n",
    "print(results_hier_k_df)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].plot(results_hier_k_df['K'], results_hier_k_df['Silhouette'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_title('Silhouette Score vs K (Hierarchical)')\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(results_hier_k_df['K'], results_hier_k_df['Davies-Bouldin'], 'ro-', linewidth=2, markersize=8)\n",
    "axes[1].set_title('Davies-Bouldin Index vs K (Hierarchical)')\n",
    "axes[1].set_xlabel('K')\n",
    "axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(results_hier_k_df['K'], results_hier_k_df['Calinski-Harabasz'], 'go-', linewidth=2, markersize=8)\n",
    "axes[2].set_title('Calinski-Harabasz Index vs K (Hierarchical)')\n",
    "axes[2].set_xlabel('K')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization of Clustering Results\n",
    "### 8.1 PCA for 2D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(clustering_data_scaled)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Visualize K-Means Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Means clustering\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# With preprocessing\n",
    "scatter1 = axes[0].scatter(data_pca[:, 0], data_pca[:, 1], \n",
    "                           c=labels_kmeans_preprocessed, cmap='viridis', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_title(f'K-Means WITH Preprocessing (K={optimal_k})')\n",
    "axes[0].set_xlabel('First Principal Component')\n",
    "axes[0].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Without preprocessing (need to transform to same PCA space)\n",
    "data_pca_no_preprocess = pca.transform(scaler_standard.transform(clustering_data_filled))\n",
    "scatter2 = axes[1].scatter(data_pca_no_preprocess[:, 0], data_pca_no_preprocess[:, 1], \n",
    "                           c=labels_kmeans_no_preprocess, cmap='viridis', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_title(f'K-Means WITHOUT Preprocessing (K={optimal_k})')\n",
    "axes[1].set_xlabel('First Principal Component')\n",
    "axes[1].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Visualize Hierarchical Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Hierarchical clustering\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# With preprocessing\n",
    "scatter1 = axes[0].scatter(data_pca[:, 0], data_pca[:, 1], \n",
    "                           c=labels_hierarchical_preprocessed, cmap='plasma', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_title(f'Hierarchical WITH Preprocessing (K={optimal_k})')\n",
    "axes[0].set_xlabel('First Principal Component')\n",
    "axes[0].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Without preprocessing\n",
    "scatter2 = axes[1].scatter(data_pca_no_preprocess[:, 0], data_pca_no_preprocess[:, 1], \n",
    "                           c=labels_hierarchical_no_preprocess, cmap='plasma', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_title(f'Hierarchical WITHOUT Preprocessing (K={optimal_k})')\n",
    "axes[1].set_xlabel('First Principal Component')\n",
    "axes[1].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Compare K-Means vs Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = axes[0].scatter(data_pca[:, 0], data_pca[:, 1], \n",
    "                           c=labels_kmeans_preprocessed, cmap='viridis', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_title(f'K-Means Clustering (K={optimal_k})')\n",
    "axes[0].set_xlabel('First Principal Component')\n",
    "axes[0].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Hierarchical\n",
    "scatter2 = axes[1].scatter(data_pca[:, 0], data_pca[:, 1], \n",
    "                           c=labels_hierarchical_preprocessed, cmap='plasma', \n",
    "                           alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_title(f'Hierarchical Clustering (K={optimal_k})')\n",
    "axes[1].set_xlabel('First Principal Component')\n",
    "axes[1].set_ylabel('Second Principal Component')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Comparison and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Method': [\n",
    "        'K-Means (With Preprocessing)',\n",
    "        'K-Means (Without Preprocessing)',\n",
    "        'Hierarchical (With Preprocessing)',\n",
    "        'Hierarchical (Without Preprocessing)'\n",
    "    ],\n",
    "    'Silhouette Score': [\n",
    "        silhouette_kmeans,\n",
    "        silhouette_kmeans_no,\n",
    "        silhouette_hierarchical,\n",
    "        silhouette_hierarchical_no\n",
    "    ],\n",
    "    'Davies-Bouldin Index': [\n",
    "        davies_bouldin_kmeans,\n",
    "        davies_bouldin_kmeans_no,\n",
    "        davies_bouldin_hierarchical,\n",
    "        davies_bouldin_hierarchical_no\n",
    "    ],\n",
    "    'Calinski-Harabasz Index': [\n",
    "        calinski_kmeans,\n",
    "        calinski_kmeans_no,\n",
    "        calinski_hierarchical,\n",
    "        calinski_hierarchical_no\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON: ALL METHODS\")\n",
    "print(\"=\"*80)\n",
    "print(final_comparison.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "methods = final_comparison['Method'].tolist()\n",
    "x_pos = np.arange(len(methods))\n",
    "\n",
    "# Silhouette Score\n",
    "axes[0].bar(x_pos, final_comparison['Silhouette Score'], color=['green', 'lightgreen', 'blue', 'lightblue'])\n",
    "axes[0].set_title('Silhouette Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Score (Higher is Better)', fontsize=12)\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "axes[1].bar(x_pos, final_comparison['Davies-Bouldin Index'], color=['green', 'lightgreen', 'blue', 'lightblue'])\n",
    "axes[1].set_title('Davies-Bouldin Index Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Index (Lower is Better)', fontsize=12)\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz Index\n",
    "axes[2].bar(x_pos, final_comparison['Calinski-Harabasz Index'], color=['green', 'lightgreen', 'blue', 'lightblue'])\n",
    "axes[2].set_title('Calinski-Harabasz Index Comparison', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Index (Higher is Better)', fontsize=12)\n",
    "axes[2].set_xticks(x_pos)\n",
    "axes[2].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Insights and Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to original data\n",
    "tourism_clustered = tourism_merged.copy()\n",
    "tourism_clustered['Cluster_KMeans'] = labels_kmeans_preprocessed\n",
    "tourism_clustered['Cluster_Hierarchical'] = labels_hierarchical_preprocessed\n",
    "\n",
    "print(\"\\n=== Sample of Clustered Data ===\")\n",
    "print(tourism_clustered.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics (K-Means)\n",
    "print(\"\\n=== K-Means Cluster Characteristics ===\")\n",
    "for cluster in range(optimal_k):\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    cluster_data = clustering_data_filled[labels_kmeans_preprocessed == cluster]\n",
    "    print(f\"Size: {len(cluster_data)} destinations\")\n",
    "    print(\"Mean values:\")\n",
    "    print(cluster_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics (Hierarchical)\n",
    "print(\"\\n=== Hierarchical Cluster Characteristics ===\")\n",
    "for cluster in range(optimal_k):\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    cluster_data = clustering_data_filled[labels_hierarchical_preprocessed == cluster]\n",
    "    print(f\"Size: {len(cluster_data)} destinations\")\n",
    "    print(\"Mean values:\")\n",
    "    print(cluster_data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### Dampak Preprocessing:\n",
    "- **Missing values handling**: Penting untuk menghindari error dan bias\n",
    "- **Outlier treatment**: Meningkatkan stabilitas clustering\n",
    "- **Feature scaling**: Sangat penting untuk algoritma berbasis jarak\n",
    "\n",
    "### Perbandingan Algoritma:\n",
    "- **K-Means**: \n",
    "  - Cepat dan efisien\n",
    "  - Sensitif terhadap inisialisasi\n",
    "  - Cluster berbentuk spherical\n",
    "  \n",
    "- **Hierarchical**: \n",
    "  - Tidak memerlukan jumlah cluster di awal\n",
    "  - Dapat menangkap struktur hierarki\n",
    "  - Lebih lambat untuk dataset besar\n",
    "\n",
    "### Parameter Tuning:\n",
    "- Jumlah cluster (K) sangat mempengaruhi hasil\n",
    "- Linkage method pada hierarchical clustering memberikan hasil berbeda\n",
    "- Gunakan multiple metrics untuk evaluasi yang komprehensif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clustered data to CSV\n",
    "tourism_clustered.to_csv('tourism_clustered_results.csv', index=False)\n",
    "print(\"Clustered data exported to 'tourism_clustered_results.csv'\")\n",
    "\n",
    "# Export comparison results\n",
    "final_comparison.to_csv('clustering_comparison_results.csv', index=False)\n",
    "print(\"Comparison results exported to 'clustering_comparison_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}